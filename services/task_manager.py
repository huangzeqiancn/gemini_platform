# services/task_manager.py
import sys
import os
import logging
import asyncio
import json
import uuid
import hmac
import hashlib
import base64
import datetime
import requests
from sqlalchemy.orm import Session
import database as db
from database import SessionLocal

# ç¡®ä¿èƒ½æ‰¾åˆ°æ ¹ç›®å½•ä¸‹çš„ parser_utils
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
if parent_dir not in sys.path:
    sys.path.append(parent_dir)

from parser_utils import extract_standard_data # å®Œç¾åˆ©ç”¨ä½ çš„æ–°æ–‡ä»¶
# åœ¨ task_manager.py é¡¶éƒ¨æ·»åŠ 
from auth_utils import get_hmac_auth
from services.scraper import run_single_scrape

def start_batch_task(task_id: int, api_id: int, prompts: list, system_instruction: str, thinking: str = "minimal"):
    """
    åå°æ‰¹é‡å¤„ç†é€»è¾‘ - å®Œæ•´ä¿®å¤ç‰ˆ
    1. å¢åŠ äº† thinking å‚æ•°æ¥æ”¶ï¼Œé˜²æ­¢å‚æ•°ä¸ªæ•°ä¸åŒ¹é…å´©æºƒ
    2. å¢å¼ºäº† task å¯¹è±¡çš„å¥å£®æ€§
    """
    s = SessionLocal()
    task = None  # æå‰å£°æ˜ï¼Œé˜²æ­¢ finally å—æŠ¥é”™
    
    try:
        # 1. è·å–ä»»åŠ¡
        task = s.query(db.ScrapeTask).filter(db.ScrapeTask.id == task_id).first()
        if not task:
            print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°ä»»åŠ¡ ID {task_id}")
            return

        # 2. è¡¥å…¨ task å¯¹è±¡çš„ thinking_level (ä»¥é˜²ä¸‡ä¸€)
        # å¦‚æœæ•°æ®åº“é‡Œçš„å€¼ä¸º Noneï¼Œå°†ä¼ è¿›æ¥çš„ thinking å€¼è¡¥ç»™å®ƒ
        if not task.thinking_level:
            task.thinking_level = thinking

        # 3. è·å–å…³è”é…ç½® (åˆ©ç”¨ SQLAlchemy relationship)
        config = task.api_config
        template = task.template

        if not config:
            print(f"âŒ é”™è¯¯ï¼šä»»åŠ¡ {task_id} æœªå…³è”æœ‰æ•ˆçš„ API é…ç½®")
            task.status = "failed"
            s.commit()
            return

        # 4. æ›´æ–°ä»»åŠ¡ä¸ºè¿è¡Œä¸­
        task.status = "running"
        # æç¤ºï¼šå¦‚æœä½ å¸Œæœ›ç”±å‰ç«¯æ§åˆ¶æ˜¯å¦å¼€å¯æœç´¢ï¼Œè¯·ä¸è¦åœ¨è¿™é‡Œå†™æ­» True
        task.use_google_search = True 
        s.commit()

        # 5. å¾ªç¯æ‰§è¡ŒæŠ“å–
        for p_text in prompts:
            # è°ƒç”¨ scraper.py é‡Œçš„å‡½æ•°
            # æ³¨æ„ï¼šè¿™é‡Œçš„ task å¯¹è±¡åœ¨å½“å‰ Session(s) ä¸­æ˜¯æ´»çš„
            success = run_single_scrape(
                task=task, 
                api_config=config, 
                prompt=p_text, 
                system_instruction=system_instruction
            )
            print(f"ğŸ“Š Prompt: {p_text[:20]}... | æ‰§è¡Œç»“æœ: {'âœ… æˆåŠŸ' if success else 'âŒ å¤±è´¥'}")

        # 6. ä»»åŠ¡æ­£å¸¸ç»“æŸ
        task.status = "completed"
        s.commit()

    except Exception as e:
        print(f"ğŸš¨ ä»»åŠ¡ä¸»å¾ªç¯å´©æºƒ: {str(e)}")
        if s and task:
            try:
                task.status = "failed"
                s.commit()
            except:
                pass
    finally:
        if s:
            s.close()